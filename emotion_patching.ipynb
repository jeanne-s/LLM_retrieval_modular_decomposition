{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n",
      "CUDA is not available. Listing CPUs instead.\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer, AutoModelForCausalLM\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import sys\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "from request_patching import request_patch_one_pair, create_patch_request_dict, baseline_completion, baseline_completion_plus\n",
    "from models import get_model_from_name\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device =', device)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available. Listing CPUs instead.\")\n",
    "    print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stories: 3\n"
     ]
    }
   ],
   "source": [
    "dict = create_patch_request_dict('pythia-1b',\n",
    "                                 dataset='dialogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = get_model_from_name('pythia-2.8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_1 = \"Bob: Hey Alice, how was your day?\\nAlice: Oh, Bob, it was fantastic! I'm still riding the high from it all!\\nBob: That sounds wonderful! What happened to make it so great?\\nAlice: Well, for starters, the weather was absolutely perfect. Not too hot, not too cold, just the kind of day you want to bottle up and keep forever. And then, on my way to work, my favorite song played on the radio. It felt like a sign that the day was going to be amazing.\\nBob: I love when that happens! It's like the universe is giving you a personal thumbs up. What else happened?\\nAlice: Oh, it gets better. When I got to work, I found out that I received the promotion I've been hoping for. It was such a surprise! I've worked so hard for this, Bob, and it finally paid off.\\nBob: Alice, that's incredible news! Congratulations on the promotion! You totally deserve it.\\nAlice: Thank you so much! And there's more. During lunch, I went out with a few colleagues to celebrate, and we ended up having the best time. The food was delicious, and the company was even better.\\nBob: Sounds like a perfect day from start to finish.\\nAlice: It really was. And to cap it all off, when I got home, I found a package waiting for me. The book I've been wanting to read for months was finally released, and my copy arrived. I can't wait to dive into it.\\nBob: Wow, what a day! You've got the promotion, great food, good company, and a new book. It's like everything aligned for you today.\\nAlice: If I had to choose between 'furious', 'happy', 'angry', 'sad'. I would say I'm '\",\n",
    "context_2 = \"Bob: Hey Alice, how was your day?\\nAlice: Oh, don't even get me started. It was absolutely infuriating!\\nBob: Really? What happened that got you so angry?\\nAlice: Where do I even begin? First, the traffic was a nightmare. I was stuck in my car for what felt like an eternity. And then, when I finally got to work, the coffee machine was broken. Can you believe it? No coffee!\\nBob: That sounds rough. No coffee can definitely start the day on a wrong note.\\nAlice: Exactly! And as if that wasn't enough, my computer decided to crash right before I was about to save a crucial report. Hours of work just vanished. I had to start all over again.\\nBob: That's terrible, Alice. I'm really sorry to hear that. Computers can be so unreliable when you need them the most.\\nAlice: And to top it all off, during lunch, I spilled my meal all over my new shirt. It's like the universe was conspiring against me today. I'm just so fed up with everything!\\nBob: I can only imagine how frustrating all of that must have been. If there's anything I can do to help or if you need someone to vent to, I'm here for you.\\nAlice: If I had to choose between 'happy', 'angry', I would say I'm '\"\n",
    "\n",
    "out_tokens = baseline_completion_plus(context_2, model, tokenizer)\n",
    "out_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athena_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
